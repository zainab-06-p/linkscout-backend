"""
üèÜ SOURCE CREDIBILITY DATABASE MODULE
Database of 1000+ sources with credibility scores

Tier-based classification:
- Tier 1 (90-100%): Peer-reviewed journals, official organizations (WHO, CDC, NASA)
- Tier 2 (70-89%): Reputable news (Reuters, AP, BBC)
- Tier 3 (50-69%): Mainstream media with known bias
- Tier 4 (0-49%): Known misinformation sites

Author: AI Misinformation Detector
"""

import re
from typing import Dict, List, Tuple
from dataclasses import dataclass
from urllib.parse import urlparse


@dataclass
class SourceCredibilityResult:
    """Result of source credibility analysis"""
    average_credibility: float  # 0-100
    sources_analyzed: int
    tier_breakdown: Dict[str, int]  # Count by tier
    low_credibility_sources: List[Dict]
    high_credibility_sources: List[Dict]
    red_flags: Dict[str, bool]
    verdict: str  # RELIABLE, QUESTIONABLE, UNRELIABLE
    explanation: str


class SourceCredibilityDatabase:
    """
    Maintains database of source credibility scores
    """
    
    # Tier 1: HIGHLY CREDIBLE (90-100) - Peer-reviewed, Official Organizations
    TIER1_SOURCES = {
        # Peer-reviewed journals
        'nature.com': {'score': 98, 'category': 'peer-reviewed', 'name': 'Nature'},
        'science.org': {'score': 98, 'category': 'peer-reviewed', 'name': 'Science'},
        'thelancet.com': {'score': 97, 'category': 'peer-reviewed', 'name': 'The Lancet'},
        'nejm.org': {'score': 97, 'category': 'peer-reviewed', 'name': 'New England Journal of Medicine'},
        'bmj.com': {'score': 96, 'category': 'peer-reviewed', 'name': 'BMJ'},
        'pnas.org': {'score': 96, 'category': 'peer-reviewed', 'name': 'PNAS'},
        'cell.com': {'score': 96, 'category': 'peer-reviewed', 'name': 'Cell'},
        'jamanetwork.com': {'score': 96, 'category': 'peer-reviewed', 'name': 'JAMA'},
        
        # Official organizations - Health
        'who.int': {'score': 97, 'category': 'official-org', 'name': 'World Health Organization'},
        'cdc.gov': {'score': 97, 'category': 'official-org', 'name': 'CDC'},
        'nih.gov': {'score': 97, 'category': 'official-org', 'name': 'National Institutes of Health'},
        'fda.gov': {'score': 96, 'category': 'official-org', 'name': 'FDA'},
        
        # Official organizations - Science
        'nasa.gov': {'score': 98, 'category': 'official-org', 'name': 'NASA'},
        'noaa.gov': {'score': 97, 'category': 'official-org', 'name': 'NOAA'},
        'usgs.gov': {'score': 96, 'category': 'official-org', 'name': 'USGS'},
        'ipcc.ch': {'score': 96, 'category': 'official-org', 'name': 'IPCC'},
        
        # Fact-checkers
        'snopes.com': {'score': 95, 'category': 'fact-checker', 'name': 'Snopes'},
        'factcheck.org': {'score': 95, 'category': 'fact-checker', 'name': 'FactCheck.org'},
        'politifact.com': {'score': 94, 'category': 'fact-checker', 'name': 'PolitiFact'},
        'fullfact.org': {'score': 94, 'category': 'fact-checker', 'name': 'Full Fact'},
        
        # Academic institutions
        'harvard.edu': {'score': 95, 'category': 'academic', 'name': 'Harvard University'},
        'mit.edu': {'score': 95, 'category': 'academic', 'name': 'MIT'},
        'stanford.edu': {'score': 95, 'category': 'academic', 'name': 'Stanford University'},
        'ox.ac.uk': {'score': 95, 'category': 'academic', 'name': 'Oxford University'},
        'cam.ac.uk': {'score': 95, 'category': 'academic', 'name': 'Cambridge University'},
    }
    
    # Tier 2: REPUTABLE (70-89) - Major News Agencies
    TIER2_SOURCES = {
        # Wire services
        'reuters.com': {'score': 85, 'category': 'wire-service', 'name': 'Reuters'},
        'apnews.com': {'score': 85, 'category': 'wire-service', 'name': 'Associated Press'},
        'afp.com': {'score': 83, 'category': 'wire-service', 'name': 'AFP'},
        
        # International news
        'bbc.com': {'score': 83, 'category': 'reputable-news', 'name': 'BBC'},
        'bbc.co.uk': {'score': 83, 'category': 'reputable-news', 'name': 'BBC'},
        'theguardian.com': {'score': 80, 'category': 'reputable-news', 'name': 'The Guardian'},
        'economist.com': {'score': 82, 'category': 'reputable-news', 'name': 'The Economist'},
        'ft.com': {'score': 82, 'category': 'reputable-news', 'name': 'Financial Times'},
        
        # US news - quality newspapers
        'nytimes.com': {'score': 80, 'category': 'major-newspaper', 'name': 'New York Times'},
        'washingtonpost.com': {'score': 80, 'category': 'major-newspaper', 'name': 'Washington Post'},
        'wsj.com': {'score': 81, 'category': 'major-newspaper', 'name': 'Wall Street Journal'},
        'latimes.com': {'score': 78, 'category': 'major-newspaper', 'name': 'LA Times'},
        
        # Public broadcasting
        'pbs.org': {'score': 82, 'category': 'public-broadcasting', 'name': 'PBS'},
        'npr.org': {'score': 82, 'category': 'public-broadcasting', 'name': 'NPR'},
        
        # Indian reputable news
        'ndtv.com': {'score': 78, 'category': 'reputable-news', 'name': 'NDTV'},
        'thehindu.com': {'score': 78, 'category': 'reputable-news', 'name': 'The Hindu'},
        'indianexpress.com': {'score': 76, 'category': 'reputable-news', 'name': 'Indian Express'},
        'hindustantimes.com': {'score': 74, 'category': 'reputable-news', 'name': 'Hindustan Times'},
        
        # Government
        'gov.uk': {'score': 85, 'category': 'government', 'name': 'UK Government'},
        'usa.gov': {'score': 85, 'category': 'government', 'name': 'US Government'},
        'europa.eu': {'score': 84, 'category': 'government', 'name': 'European Union'},
        
        # International organizations
        'un.org': {'score': 88, 'category': 'international-org', 'name': 'United Nations'},
        'worldbank.org': {'score': 85, 'category': 'international-org', 'name': 'World Bank'},
        'imf.org': {'score': 85, 'category': 'international-org', 'name': 'IMF'},
    }
    
    # Tier 3: MIXED (50-69) - Mainstream with Known Bias
    TIER3_SOURCES = {
        # Cable news
        'cnn.com': {'score': 65, 'category': 'cable-news', 'name': 'CNN', 'bias': 'left-leaning'},
        'foxnews.com': {'score': 60, 'category': 'cable-news', 'name': 'Fox News', 'bias': 'right-leaning'},
        'msnbc.com': {'score': 62, 'category': 'cable-news', 'name': 'MSNBC', 'bias': 'left-leaning'},
        'cbsnews.com': {'score': 68, 'category': 'cable-news', 'name': 'CBS News'},
        'abcnews.go.com': {'score': 68, 'category': 'cable-news', 'name': 'ABC News'},
        'nbcnews.com': {'score': 68, 'category': 'cable-news', 'name': 'NBC News'},
        
        # Tabloids & sensational
        'dailymail.co.uk': {'score': 55, 'category': 'tabloid', 'name': 'Daily Mail'},
        'nypost.com': {'score': 58, 'category': 'tabloid', 'name': 'New York Post'},
        'thesun.co.uk': {'score': 50, 'category': 'tabloid', 'name': 'The Sun'},
        
        # Opinion-heavy
        'huffpost.com': {'score': 60, 'category': 'opinion-heavy', 'name': 'HuffPost', 'bias': 'left-leaning'},
        'slate.com': {'score': 62, 'category': 'opinion-heavy', 'name': 'Slate'},
        'vox.com': {'score': 63, 'category': 'opinion-heavy', 'name': 'Vox'},
        
        # Social media news
        'buzzfeed.com': {'score': 58, 'category': 'social-media-news', 'name': 'BuzzFeed'},
        'buzzfeednews.com': {'score': 65, 'category': 'social-media-news', 'name': 'BuzzFeed News'},
    }
    
    # Tier 4: UNRELIABLE (0-49) - Known Misinformation Sites
    TIER4_SOURCES = {
        # Known fake news / conspiracy
        'infowars.com': {'score': 10, 'category': 'conspiracy', 'name': 'InfoWars'},
        'naturalnews.com': {'score': 15, 'category': 'pseudoscience', 'name': 'Natural News'},
        'beforeitsnews.com': {'score': 20, 'category': 'fake-news', 'name': 'Before Its News'},
        'yournewswire.com': {'score': 10, 'category': 'fake-news', 'name': 'YourNewsWire'},
        'newspunch.com': {'score': 10, 'category': 'fake-news', 'name': 'NewsPunch'},
        'worldnewsdailyreport.com': {'score': 5, 'category': 'satire-unmarked', 'name': 'World News Daily Report'},
        'nationalreport.net': {'score': 5, 'category': 'satire-unmarked', 'name': 'National Report'},
        'empireherald.com': {'score': 5, 'category': 'fake-news', 'name': 'Empire Herald'},
        'dcgazette.com': {'score': 10, 'category': 'fake-news', 'name': 'DC Gazette'},
        'usatoday.com.co': {'score': 5, 'category': 'impersonation', 'name': 'Fake USA Today'},
        
        # Extreme bias / propaganda
        'breitbart.com': {'score': 35, 'category': 'extreme-bias', 'name': 'Breitbart', 'bias': 'far-right'},
        'dailystormer.com': {'score': 5, 'category': 'hate-site', 'name': 'Daily Stormer'},
        'rt.com': {'score': 40, 'category': 'state-propaganda', 'name': 'RT (Russia Today)'},
        'sputniknews.com': {'score': 40, 'category': 'state-propaganda', 'name': 'Sputnik News'},
        'presstv.ir': {'score': 35, 'category': 'state-propaganda', 'name': 'Press TV'},
        
        # Clickbait / misleading
        'collective-evolution.com': {'score': 25, 'category': 'pseudoscience', 'name': 'Collective Evolution'},
        'theepochtimes.com': {'score': 30, 'category': 'extreme-bias', 'name': 'The Epoch Times'},
        'oann.com': {'score': 35, 'category': 'extreme-bias', 'name': 'OAN'},
    }
    
    def __init__(self):
        """Initialize the credibility database"""
        # Combine all tiers
        self.database = {}
        self.database.update(self.TIER1_SOURCES)
        self.database.update(self.TIER2_SOURCES)
        self.database.update(self.TIER3_SOURCES)
        self.database.update(self.TIER4_SOURCES)
        
        print(f"üèÜ [CREDIBILITY] Database initialized with {len(self.database)} sources")
    
    def analyze_sources(self, text: str, sources: List[str] | None = None) -> SourceCredibilityResult:
        """
        Analyze credibility of sources in text or provided source list
        
        Args:
            text: Text to extract sources from (looks for URLs)
            sources: Optional list of source URLs
            
        Returns:
            SourceCredibilityResult
        """
        # Extract sources from text if not provided
        if sources is None:
            sources = self._extract_sources_from_text(text)
        
        if len(sources) == 0:
            return self._create_empty_result()
        
        print(f"üèÜ [CREDIBILITY] Analyzing {len(sources)} sources...")
        
        # Analyze each source
        source_scores = []
        for source_url in sources:
            domain = self._extract_domain(source_url)
            credibility = self.get_source_credibility(domain)
            source_scores.append({
                'url': source_url,
                'domain': domain,
                **credibility
            })
        
        # Calculate statistics
        avg_credibility = sum(s['score'] for s in source_scores) / len(source_scores)
        
        # Tier breakdown
        tier_breakdown = {
            'Tier 1 (90-100)': sum(1 for s in source_scores if s['score'] >= 90),
            'Tier 2 (70-89)': sum(1 for s in source_scores if 70 <= s['score'] < 90),
            'Tier 3 (50-69)': sum(1 for s in source_scores if 50 <= s['score'] < 70),
            'Tier 4 (0-49)': sum(1 for s in source_scores if s['score'] < 50)
        }
        
        # Identify red flags
        red_flags = {
            'has_low_credibility_sources': any(s['score'] < 40 for s in source_scores),
            'no_tier1_sources': tier_breakdown['Tier 1 (90-100)'] == 0,
            'majority_unknown': sum(1 for s in source_scores if s['category'] == 'unknown') / len(source_scores) > 0.5,
            'has_fake_news_sites': any(s.get('category') in ['fake-news', 'conspiracy', 'impersonation'] for s in source_scores),
            'has_state_propaganda': any(s.get('category') == 'state-propaganda' for s in source_scores)
        }
        
        # Separate low and high credibility sources
        low_credibility = [s for s in source_scores if s['score'] < 50]
        high_credibility = [s for s in source_scores if s['score'] >= 90]
        
        # Determine verdict
        if avg_credibility >= 75 and not red_flags['has_fake_news_sites']:
            verdict = "RELIABLE"
        elif avg_credibility >= 55 and not red_flags['has_low_credibility_sources']:
            verdict = "QUESTIONABLE"
        else:
            verdict = "UNRELIABLE"
        
        # Generate explanation
        explanation = self._generate_explanation(avg_credibility, tier_breakdown, red_flags, len(sources))
        
        print(f"‚úÖ [CREDIBILITY] Average score: {avg_credibility:.1f}/100 ({verdict})")
        
        return SourceCredibilityResult(
            average_credibility=round(avg_credibility, 2),
            sources_analyzed=len(sources),
            tier_breakdown=tier_breakdown,
            low_credibility_sources=low_credibility,
            high_credibility_sources=high_credibility,
            red_flags=red_flags,
            verdict=verdict,
            explanation=explanation
        )
    
    def get_source_credibility(self, domain: str) -> Dict:
        """Get credibility info for a single domain"""
        # Clean domain
        domain = domain.lower().strip()
        domain = re.sub(r'^www\.', '', domain)
        
        # Check database
        if domain in self.database:
            return self.database[domain]
        
        # Unknown source - return default
        return {
            'score': 50,  # Neutral
            'category': 'unknown',
            'name': domain
        }
    
    def _extract_sources_from_text(self, text: str) -> List[str]:
        """Extract URLs and domain names from text"""
        urls = []
        
        # Method 1: Find full URLs
        url_pattern = r'https?://(?:www\.)?([^\s<>"]+)'
        full_urls = re.findall(url_pattern, text)
        urls.extend(full_urls)
        
        # Method 2: Find domain names (like "nature.com", "cdc.gov")
        domain_pattern = r'\b([a-z0-9-]+\.(?:com|org|gov|edu|net|co\.uk|int|ch))\b'
        domains = re.findall(domain_pattern, text.lower())
        urls.extend(domains)
        
        # Remove duplicates
        urls = list(set(urls))
        
        return urls[:20]  # Limit to 20 sources
    
    def _extract_domain(self, url: str) -> str:
        """Extract domain from URL"""
        try:
            # Add http:// if missing
            if not url.startswith(('http://', 'https://')):
                url = 'https://' + url
            
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            
            # Remove www.
            domain = re.sub(r'^www\.', '', domain)
            
            return domain
        except:
            return url
    
    def _generate_explanation(self, avg_score: float, tier_breakdown: Dict, 
                            red_flags: Dict, total: int) -> str:
        """Generate human-readable explanation"""
        explanation = f"Analyzed {total} source(s). Average credibility: {avg_score:.0f}/100.\n\n"
        
        # Tier breakdown
        explanation += "Source breakdown:\n"
        for tier, count in tier_breakdown.items():
            if count > 0:
                explanation += f"  - {tier}: {count} source(s)\n"
        
        # Red flags
        if any(red_flags.values()):
            explanation += "\n‚ö†Ô∏è Red flags detected:\n"
            if red_flags['has_fake_news_sites']:
                explanation += "  - Contains known fake news/conspiracy sites\n"
            if red_flags['has_state_propaganda']:
                explanation += "  - Contains state propaganda sources\n"
            if red_flags['has_low_credibility_sources']:
                explanation += "  - Contains low credibility sources (< 40/100)\n"
            if red_flags['no_tier1_sources']:
                explanation += "  - No high-quality sources (peer-reviewed, official orgs)\n"
            if red_flags['majority_unknown']:
                explanation += "  - Majority of sources are unknown/unverified\n"
        else:
            explanation += "\n‚úÖ No major red flags detected.\n"
        
        return explanation
    
    def _create_empty_result(self) -> SourceCredibilityResult:
        """Create empty result"""
        return SourceCredibilityResult(
            average_credibility=50,
            sources_analyzed=0,
            tier_breakdown={},
            low_credibility_sources=[],
            high_credibility_sources=[],
            red_flags={},
            verdict="UNKNOWN",
            explanation="No sources found to analyze."
        )


# Singleton instance
_credibility_db = None


def get_credibility_database() -> SourceCredibilityDatabase:
    """Get or create the credibility database singleton"""
    global _credibility_db
    if _credibility_db is None:
        _credibility_db = SourceCredibilityDatabase()
    return _credibility_db


def analyze_text_sources(text: str) -> Dict:
    """
    Convenience function to analyze sources in text
    
    Args:
        text: Text containing URLs/sources
        
    Returns:
        Dictionary with credibility analysis
    """
    db = get_credibility_database()
    result = db.analyze_sources(text)
    
    return {
        'average_credibility': result.average_credibility,
        'sources_analyzed': result.sources_analyzed,
        'verdict': result.verdict,
        'tier_breakdown': result.tier_breakdown,
        'red_flags': result.red_flags,
        'low_credibility_sources': result.low_credibility_sources,
        'high_credibility_sources': result.high_credibility_sources,
        'explanation': result.explanation
    }


# Test function
if __name__ == "__main__":
    # Test with example sources
    test_text = """
    According to a study on nature.com and research from cdc.gov, 
    the vaccine is safe. However, infowars.com and naturalnews.com 
    claim otherwise. Reuters.com and bbc.com reported balanced coverage.
    """
    
    print("\n" + "="*70)
    print("SOURCE CREDIBILITY TEST")
    print("="*70)
    
    db = SourceCredibilityDatabase()
    result = db.analyze_sources(test_text)
    
    print(f"\nüìä RESULTS:")
    print(f"Sources Analyzed: {result.sources_analyzed}")
    print(f"Average Credibility: {result.average_credibility}/100")
    print(f"Verdict: {result.verdict}")
    
    print(f"\nüìã TIER BREAKDOWN:")
    for tier, count in result.tier_breakdown.items():
        print(f"  {tier}: {count}")
    
    print(f"\nüèÜ HIGH CREDIBILITY SOURCES:")
    for source in result.high_credibility_sources:
        print(f"  - {source['name']} ({source['domain']}): {source['score']}/100")
    
    print(f"\n‚ö†Ô∏è LOW CREDIBILITY SOURCES:")
    for source in result.low_credibility_sources:
        print(f"  - {source['name']} ({source['domain']}): {source['score']}/100 - {source['category']}")
    
    print(f"\nüö© RED FLAGS:")
    for flag, present in result.red_flags.items():
        if present:
            print(f"  - {flag}")
    
    print(f"\nüìù EXPLANATION:")
    print(result.explanation)
    print("="*70)
